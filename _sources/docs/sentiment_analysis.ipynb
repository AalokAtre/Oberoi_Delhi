{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Classifier And Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will leverage the spacy library to train a sentiment classifier. We will then use this trained model to predict a few custom reviews and check if the model is able to predict the sentiment of these reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import spacy\n",
    "import spacy_transformers\n",
    "\n",
    "# Storing docs in binary format\n",
    "from spacy.tokens import DocBin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2896, 6)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/final_dataset.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting our dataset into train and test sets in 80-20 split. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2317, 6) (579, 6)\n"
     ]
    }
   ],
   "source": [
    "train = df.sample(frac = 0.8, random_state = 25)\n",
    "test = df.drop(train.index)\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the required spacy package. English pipeline optimized for CPU. Components: tok2vec, tagger, parser, senter, ner, attribute_ruler, lemmatizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "nlp=spacy.load(\"en_core_web_sm\")\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First step is to create tuples which are pairs of text along with sentiments. Creating tuples for both train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['tuples'] = train.apply(lambda row: (row['Customer Review'],row['Customer Rating']), axis=1)\n",
    "train = train['tuples'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating tuples for test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['tuples'] = test.apply(lambda row: (row['Customer Review'],row['Customer Rating']), axis=1)\n",
    "test = test['tuples'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking one of the tuples that were created above. As you can see it is a combination of review and its sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('great property warm welcome staff food delicious great stay definitely recommend family friend staff go extra mile stay comfortable',\n",
       " 'Excellent')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second step is to create a spaCy document for each tuple in the train and test dataset with the help of a transformer model (en_core_web_sm)using a spacy pipeline called nlp. Each tuple is nothing but text and its sentiments. Note here that we map 4 and 5 star ratings (Excellent and Very Good as positive sentiments), 1 and 2 start rating (Poor and Terrible) as negative and everything else i.e 3 star as Neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document(data):\n",
    "  text = []\n",
    "  for doc, label in nlp.pipe(data, as_tuples = True):\n",
    "    if (label=='Excellent'):\n",
    "      doc.cats['positive'] = 1\n",
    "      doc.cats['negative'] = 0\n",
    "      doc.cats['neutral']  = 0\n",
    "    elif (label=='Very Good'):\n",
    "      doc.cats['positive'] = 1\n",
    "      doc.cats['negative'] = 0\n",
    "      doc.cats['neutral']  = 0\n",
    "    elif (label=='Poor'):\n",
    "      doc.cats['positive'] = 0\n",
    "      doc.cats['negative'] = 1\n",
    "      doc.cats['neutral']  = 0\n",
    "    elif (label=='Terrible'):\n",
    "      doc.cats['positive'] = 0\n",
    "      doc.cats['negative'] = 1\n",
    "      doc.cats['neutral']  = 0\n",
    "    else:\n",
    "      doc.cats['positive'] = 0\n",
    "      doc.cats['negative'] = 0\n",
    "      doc.cats['neutral']  = 1\n",
    "    text.append(doc)\n",
    "  \n",
    "  return(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 0:00:02.901909\n"
     ]
    }
   ],
   "source": [
    "# Calculate the time for converting into binary document for train dataset\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "#passing the train dataset into function 'document'\n",
    "train_docs = document(train)\n",
    "\n",
    "#Creating binary document using DocBin function in spaCy\n",
    "doc_bin = DocBin(docs = train_docs)\n",
    "\n",
    "#Saving the binary document as train.spacy\n",
    "doc_bin.to_disk(\"train.spacy\")\n",
    "end_time = datetime.now()\n",
    "\n",
    "#Printing the time duration for train dataset\n",
    "print('Duration: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 0:00:00.758820\n"
     ]
    }
   ],
   "source": [
    "# Calculate the time for converting into binary document for test dataset\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "#passing the test dataset into function 'document'\n",
    "test_docs = document(test)\n",
    "doc_bin = DocBin(docs = test_docs)\n",
    "doc_bin.to_disk(\"test.spacy\")\n",
    "end_time = datetime.now()\n",
    "\n",
    "#Printing the time duration for test dataset\n",
    "print('Duration: {}'.format(end_time - start_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the base spacy config file to define our own configuration for model parameters. Default configurtions are more than enough for us. All we need to do is define the paths for train and dev files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
      "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
      "config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    }
   ],
   "source": [
    "#Converting base configuration into full config file\n",
    "!python -m spacy init fill-config ./base_config.cfg ./config.cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we run the script to train our spacy model to perform sentiment analysis. This model will then be saved to output updated folder from where we can leverage the trained model to predict review sentiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Saving to output directory: output_updated\u001b[0m\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[38;5;4mℹ To switch to GPU 0, use the option: --gpu-id 0\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[2022-12-15 23:12:14,530] [INFO] Set up nlp object from config\n",
      "[2022-12-15 23:12:14,535] [DEBUG] Loading corpus from path: test.spacy\n",
      "[2022-12-15 23:12:14,535] [DEBUG] Loading corpus from path: train.spacy\n",
      "[2022-12-15 23:12:14,535] [INFO] Pipeline: ['textcat']\n",
      "[2022-12-15 23:12:14,537] [INFO] Created vocabulary\n",
      "[2022-12-15 23:12:14,537] [INFO] Finished initializing nlp object\n",
      "[2022-12-15 23:12:15,183] [INFO] Initialized pipeline components: ['textcat']\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "[2022-12-15 23:12:15,189] [DEBUG] Loading corpus from path: test.spacy\n",
      "[2022-12-15 23:12:15,189] [DEBUG] Loading corpus from path: train.spacy\n",
      "\u001b[38;5;4mℹ Pipeline: ['textcat']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TEXTCAT  CATS_SCORE  SCORE \n",
      "---  ------  ------------  ----------  ------\n",
      "  0       0          0.22        0.00    0.00\n",
      "  0     200          9.22       32.51    0.33\n",
      "  0     400          4.65       32.51    0.33\n",
      "  0     600          5.71       32.51    0.33\n",
      "  1     800          3.84       32.51    0.33\n",
      "  1    1000          3.82       32.54    0.33\n",
      "  2    1200          3.17       32.51    0.33\n",
      "  3    1400          2.37       43.65    0.44\n",
      "  4    1600          1.10       43.65    0.44\n",
      "  5    1800          0.49       43.65    0.44\n",
      "  6    2000          0.33       43.65    0.44\n",
      "  8    2200          0.19       46.42    0.46\n",
      " 10    2400          0.15       46.42    0.46\n",
      " 12    2600          0.16       46.42    0.46\n",
      " 15    2800          0.16       46.42    0.46\n",
      " 17    3000          0.15       46.42    0.46\n",
      " 19    3200          0.12       46.42    0.46\n",
      " 21    3400          0.12       46.42    0.46\n",
      " 24    3600          0.12       46.42    0.46\n",
      " 26    3800          0.16       46.42    0.46\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "output_updated/model-last\n",
      "Duration: 0:00:14.904080\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "!python -m spacy train ./config.cfg --verbose  --output ./output_updated\n",
    "\n",
    "end_time = datetime.now()\n",
    "\n",
    "print('Duration: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"The stay was bad. The serivce was poor.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'positive': 0.25720450282096863, 'negative': 0.4230425953865051, 'neutral': 0.31975290179252625}\n"
     ]
    }
   ],
   "source": [
    "#Test the data from the best model\n",
    "nlp = spacy.load(\"output_updated/model-best\")\n",
    "demo = nlp(text)\n",
    "print(demo.cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"We had an amazing time. The rooms were very clean. The food tasted amazing and staff was very courteous\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'positive': 0.9619991779327393, 'negative': 0.013230466283857822, 'neutral': 0.024770323187112808}\n"
     ]
    }
   ],
   "source": [
    "#Test the data from the best model\n",
    "nlp = spacy.load(\"output_updated/model-best\")\n",
    "demo = nlp(text1)\n",
    "print(demo.cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = \"Stay was as expected. The service was on par with our expecations\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'positive': 0.7474048137664795, 'negative': 0.1129467636346817, 'neutral': 0.13964837789535522}\n"
     ]
    }
   ],
   "source": [
    "#Test the data from the best model\n",
    "nlp = spacy.load(\"output_updated/model-best\")\n",
    "demo = nlp(text2)\n",
    "print(demo.cats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit ('3.9.2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b3026a12acffdc9f506c0823b05e249d31fb04335d3c4999ca8eadedea0b2708"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
