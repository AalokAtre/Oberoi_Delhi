{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reviews Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Punctuation and casing within reviews is an hindrance for language processing as they pollute the dataset with their dominance and redundancies, as such we lowercase the entire review dataset and remove all the punctuation. Customer reviews also contain a lot of words that have little / no value in topic modelling or sentiment analysis. These words called the stopwords should be removed from the dataset before we perform any kind of analysis. We use a combination of pre built python packages and custom defined stopwords to clean our reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from textblob import Word\n",
    "from gensim.parsing.preprocessing import remove_stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lowercasing all the words in the dataset. We use the in built python function of.lower for this operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       excellent and highly recommended! we only spen...\n",
       "1       this was our favourite hotel whilst we visited...\n",
       "2       we stayed 2 nights at the new delhi oberoi. wh...\n",
       "3       the very best!! quality of service and food is...\n",
       "4       the service , food, location, cleanliness is e...\n",
       "                              ...                        \n",
       "2891    stayed at the oberoi for a long weekend with f...\n",
       "2892    the oberoi hotels have established a world-cla...\n",
       "2893    i've been through a few hotels in delhi over t...\n",
       "2894    this is a beautiful and luxurious hotel. unfor...\n",
       "2895    hotel is fine and food is good although pricey...\n",
       "Name: Customer Review, Length: 2896, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/cleaned_data.csv')\n",
    "df['Customer Review'] = df['Customer Review'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "df['Customer Review']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step is the remove all the punctuation from the dataset. We will use the str.replace and regex matching for this operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       excellent highly recommended spent nights left...\n",
       "1       favourite whilst visited recently refurbished ...\n",
       "2       stayed 2 nights new upgraded presidential suit...\n",
       "3       best quality service food notch quality spread...\n",
       "4       service food location cleanliness excellent be...\n",
       "                              ...                        \n",
       "2891    stayed long weekend friends arrived 1am luggag...\n",
       "2892    hotels established worldclass reputation deser...\n",
       "2893    ive hotels yearshilton hyatts marriott sofitel...\n",
       "2894    beautiful luxurious unfortunately price id exp...\n",
       "2895    fine food good pricey compared competition wat...\n",
       "Name: Customer Review, Length: 2896, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Customer Review'] = df['Customer Review'].str.replace('[^\\w\\s]', '', regex=True)\n",
    "df['Customer Review']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first check the 15 of the most common words that appear in the corpus. We will then remove stopwords using the gensim package and then define our custom stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "the       17666\n",
       "and        9939\n",
       "a          6237\n",
       "to         6112\n",
       "was        4742\n",
       "in         4733\n",
       "of         4374\n",
       "is         4095\n",
       "i          3754\n",
       "hotel      3377\n",
       "we         2882\n",
       "for        2762\n",
       "at         2615\n",
       "with       2274\n",
       "oberoi     2263\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq= pd.Series(\" \".join(df['Customer Review']).split()).value_counts()[:15]\n",
    "freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing stop words using the gensim package. The package contains a list of stopwords from the english dictionary. This will save us a lot of time of manually defininig every stopword."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hotel        3377\n",
       "oberoi       2263\n",
       "service      1976\n",
       "staff        1967\n",
       "delhi        1755\n",
       "room         1571\n",
       "stay         1386\n",
       "good         1093\n",
       "food         1072\n",
       "great        1060\n",
       "rooms         984\n",
       "stayed        900\n",
       "excellent     882\n",
       "new           866\n",
       "best          726\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim\n",
    "stop_words = gensim.parsing.preprocessing.STOPWORDS\n",
    "stop_words\n",
    "# Remove Stopwords\n",
    "df['Customer Review'] = df['Customer Review'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop_words))\n",
    "freq= pd.Series(\" \".join(df['Customer Review']).split()).value_counts()[:15]\n",
    "# Show the most common words after removal of stopwords\n",
    "freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we will provide our very own custom stopwords. For e.g Oberoi, Delhi and hotel are all stopwords in this excercise as they provide no value in topic modelling or sentiment analysis. A few others have also been added below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "service       1976\n",
       "staff         1967\n",
       "room          1571\n",
       "stay          1386\n",
       "good          1093\n",
       "food          1072\n",
       "great         1060\n",
       "rooms          984\n",
       "stayed         900\n",
       "excellent      882\n",
       "new            866\n",
       "best           726\n",
       "breakfast      702\n",
       "restaurant     686\n",
       "hotels         680\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Customer Review']\n",
    "custom_stopwords = ['hotel', 'oberoi', 'delhi', 'india', 'oberois', 'city']\n",
    "df['Customer Review'] = df['Customer Review'].apply(lambda x: \" \".join(x for x in x.split() if x not in custom_stopwords))\n",
    "freq= pd.Series(\" \".join(df['Customer Review']).split()).value_counts()[:15]\n",
    "# Show the most common words after removal of stopwords\n",
    "freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will write these cleaned reviews to a CSV file. Next step would be lemmatization of review data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/cleaned_reviews_1.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit ('3.9.2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b3026a12acffdc9f506c0823b05e249d31fb04335d3c4999ca8eadedea0b2708"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
